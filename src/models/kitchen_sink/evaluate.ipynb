{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "2a008d38f9fcd3b1bcdf3424c49b99420c19e99d92e50a69ba9e08b63c274acd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import pickle\n",
    "import dagshub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_csv('../../../data/feature/ks_train.csv')\n",
    "val_df = pd.read_csv('../../../data/feature/ks_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameters.json', 'r')as pf:\n",
    "    params = json.load(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='multi:softmax', num_class=3,\n",
    "                    silent=True, nthread=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \nParameters: { silent } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\n[18:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=600, n_jobs=1, nthread=1, num_class=3,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, silent=True,\n",
       "              subsample=1.0, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "xgbc.fit(tr_df.iloc[:, :-1], tr_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgb-classifier.pkl','wb') as pf:\n",
    "    pickle.dump(xgbc, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_len = val_df.shape[0]\n",
    "tr_sub = tr_df.sample(n=val_len, random_state=443)\n",
    "y_tr_pred = xgbc.predict(tr_sub.iloc[:, :-1])\n",
    "y_train = tr_sub.iloc[:, -1]\n",
    "\n",
    "y_ts_pred = xgbc.predict(val_df.iloc[:, :-1])\n",
    "y_test = val_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.584676910853922"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "precision_score(y_train, y_tr_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('score.json','w') as pf:\n",
    "    json.dump({'train' : {'accuracy' : accuracy_score(y_train, y_tr_pred), 'precision' : precision_score(y_train, y_tr_pred, average='weighted'), 'recall' : recall_score(y_train, y_tr_pred, average='weighted'), 'f1-score' : f1_score(y_train, y_tr_pred, average='weighted')},\n",
    "    'test' : {'accuracy' : accuracy_score(y_test, y_ts_pred), 'precision' : precision_score(y_test, y_ts_pred, average='weighted'), 'recall' : recall_score(y_test, y_ts_pred, average='weighted'), 'f1-score' : f1_score(y_test, y_ts_pred, average='weighted')}\n",
    "    }, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}